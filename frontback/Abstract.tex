%% abstract.tex
%% Shortly introduce your work here
%% Use inside the document
%% @author Patrick Holthaus (pholthau)
%% @author Viktor Richter (vrichter)


\chapter*{Abstract}%
\pdfbookmark[1]{Abstract}{Abstract}
% \addcontentsline{toc}{chapter}{Abstract}%

%% Motivation:
%% Why do we care about the problem and the results? 
Human communication is complex, dynamic and implicit.
People know when others want to interact with them. 
They know when they are addressed, whether they need to react, and to whom.
This understanding is learnt early and refined throughout the whole life.
%% Problem statement:
%% What problem are you trying to solve? What is the scope of your work (a generalized approach, or for a specific situation)?
\Glspl{artificial agent}, in contrast, do not grow up.
They are not exposed to great amounts of high quality training in interaction as humans are.
Nevertheless, if we want to interact with \glspl{artificial agent} in as we do with humans, we need them to understand our communication.
They need to recognize the states we are in, the intentions we pursue, and the behaviours we display to achieve this.
In this thesis, I investigate which human behaviours can be observed to infer the \glsatt{conversation} state and intentions of humans in interactions with \glspl{artificial agent} in a \gls{smart environment}.
%% Approach:
%% How did you go about solving or making progress on the problem?
After a detailed review of literature on the principles of human interaction and the efforts to transfer these to \glspl{artificial agent} and \glspl{smart environment}, I investigate human \glsatt{conversation} cues in interactions with different kinds of agents.
%% Results:
%% What's the answer? Put the result there, in numbers. Avoid vague, hand-waving results.
With these investigations I show that 
(1) although addressing in unconstrained interactions of single users with \glspl{device} and agents is diverse, the addressed entity can be recognized to a high degree from audio-visual cues,
(2) a \gls{robot} in a human-\gls{robot} \gls{conversational group} can utilize facial information of its interlocutors to decide whether it is addressed or not, and
(3) the \gls{conversational group} and role of a \gls{virtual agent} can be recognized by observing the motion and facial expressions of the people in its vicinity.
%% Conclusions:
%% What are the implications of your answer? Are your results general, potentially generalizable, or specific to a particular case?
The insights from these investigations and the corresponding models allow an automatic interpretation of human \glsatt{conversation} behaviour in interactions with \glspl{artificial agent}.
This can be used to create agents which better understand and utilize human communication, to make interaction more natural and effective.

\thispagestyle{empty}

\cleardoublepage
